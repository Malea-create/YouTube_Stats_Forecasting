{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "Wikipedia is an encyclopedia that covers a large amount of diverse topics. All articles are created, corrected and updated by individuals. The goal is to correctly document as many topics as possible by collecting the knowledge of a large number of people. However, some articles stand out due to their completeness, scope and presentation, and for this they are marked with the distinction of the Excellent Article. \n",
    "\n",
    "As part of the Natural Language Processing lecture, a classification of Wikipedia articles is to be carried out as a sub-task of an assignment with the goal of being able to identify excellent articles. This notebook contains the code to accomplish this goal and is structured as follows:\n",
    "\n",
    "- [1. Imports](article_classification.ipynb#1-imports)\n",
    "- [2. Enrichment of the Data](article_classification.ipynb#2-check-data-availability)\n",
    "\t- [2.1 Add Subscription Details](#thema1)\n",
    "\t- [2.2 Download Thumnails and add Path to jpg to the df](#thema2)\n",
    "- [3. Data Cleaning](article_classification.ipynb#3-data-processing)\n",
    "\t- [4.1 Define Data Cleaning](#thema1)\n",
    "\t- [4.2 Define String Encoding](#thema2)\n",
    "\t- [4.3 Apply Functions](#thema3)\n",
    "- [4. Export df]()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports\n",
    "Import the requiered libraties into the notebook.\n",
    "If some libraries are not installed, you can use the `requierements.txt` and run\n",
    "```\n",
    "$ pip install -r requirements.txt\n",
    "```\n",
    "in the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 16:41:14.307133: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/CAvideos.csv\")\n",
    "df = df[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enrichment of the Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Subscription Details for Channel Details\n",
    "\n",
    "Subscribing to a channel on YouTube can make it easier for you to watch multiple videos from the same channel. Therefore the Subscription count is a measure for the YouTubers reach. [1] According to range of the audiance that can be reached through a video, the subscription count is an important feature when forecasting the potential views of a video. \n",
    "\n",
    "In the following the `YouTube Data API v3` from `www.googleapis.com` is going to be used to add the subscription coun of the channel to the df.\n",
    "\n",
    "[1] https://tuberanker.com/blog/what-are-the-benefits-of-subscribing-to-a-youtube-channel (04.06.23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following youtube_authenticate function is available under this url: https://www.thepythoncode.com/article/using-youtube-api-in-python#google_vignette\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "\n",
    "import urllib.parse as p\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "SCOPES = [\"https://www.googleapis.com/auth/youtube.force-ssl\"]\n",
    "\n",
    "def youtube_authenticate():\n",
    "    os.environ[\"OAUTHLIB_INSECURE_TRANSPORT\"] = \"1\"\n",
    "    api_service_name = \"youtube\"\n",
    "    api_version = \"v3\"\n",
    "    client_secrets_file = \"client_secret_883243427026-gmpvuoto8cd0gsl6djl80sesaa6b5jo0.apps.googleusercontent.com.json\"\n",
    "    creds = None\n",
    "    # the file token.pickle stores the user's access and refresh tokens, and is\n",
    "    # created automatically when the authorization flow completes for the first time\n",
    "    if os.path.exists(\"token.pickle\"):\n",
    "        with open(\"token.pickle\", \"rb\") as token:\n",
    "            creds = pickle.load(token)\n",
    "    # if there are no (valid) credentials availablle, let the user log in.\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(client_secrets_file, SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        # save the credentials for the next run\n",
    "        with open(\"token.pickle\", \"wb\") as token:\n",
    "            pickle.dump(creds, token)\n",
    "\n",
    "    return build(api_service_name, api_version, credentials=creds)\n",
    "\n",
    "# authenticate to YouTube API\n",
    "youtube = youtube_authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the Youtube API Documentation for more insights: https://developers.google.com/youtube/v3/docs/subscriptions/list?hl=de&apix=true\n",
    "\n",
    "def get_channel_details(youtube, **kwargs):\n",
    "\n",
    "    request = youtube.channels().list(\n",
    "        part=\"statistics\", # just get stats\n",
    "        **kwargs\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40881/40881 [22:59<00:00, 29.63it/s]\n"
     ]
    }
   ],
   "source": [
    "# get subscription count and save it to the df\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range (0, len(df))):\n",
    "\n",
    "    try:\n",
    "\n",
    "        # get current channel Name\n",
    "        channel_name = df.iloc[i][\"channel_title\"]\n",
    "\n",
    "        # make API call to get channel infos\n",
    "        response = get_channel_details(youtube, forUsername=channel_name)\n",
    "        items = response.get(\"items\")[0]\n",
    "        statistics = items[\"statistics\"]\n",
    "\n",
    "        # get stats infos\n",
    "        subscriberCount = statistics[\"subscriberCount\"]\n",
    "\n",
    "        # save subscriptions to df\n",
    "        df.at[i,\"subscriber_count\"] = int(subscriberCount)\n",
    "\n",
    "    except:\n",
    "\n",
    "        df.at[i,\"subscriber_count\"] = np.NAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Thumnails and add Path to jpg to the df\n",
    "\n",
    "Every YouTube video is represented by a thumbnail, a small image that, along with the title and channel, serves as the “cover” of the video. Thumbnails that are interest- ing and well-framed attract viewers, while those that are confusing and low-quality encourage viewers to click else- where. As a testament to the important of a good thumb- nail, 90% of the most successful YouTube videos have cus- tom thumbnails [2]. YouTube uploaders without the time or skills to create a custom thumbnail, however, must pick one of 3 frames automatically chosen from the video. Our mission is to improve this frame selection process and help uploaders select high quality frames that will attract viewers to their channel.\n",
    "\n",
    "http://cs231n.stanford.edu/reports/2017/pdfs/710.pdf\n",
    "[2] YouTube Creator Academy. Lesson: Make click- able thumbnails. https://creatoracademy. youtube.com/page/lesson/thumbnails# yt-creators-strategies-5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:08<00:00, 58.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# load thumbnail and save picture path in df\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "df_w_jgp = df.copy()\n",
    "\n",
    "def load_and_save_thumbnail(url, iterator):\n",
    "    try:\n",
    "\n",
    "        # get unique thumbnail id \n",
    "        splitted_words = url.split(\"/\")\n",
    "        thumbnail_id = splitted_words[4]\n",
    "\n",
    "        # create filename to save thumbnail\n",
    "        file_path = f\"../Data/thumbnails/{thumbnail_id}.jpg\"\n",
    "        df_w_jgp.at[iterator,\"thumbnail_link\"] = thumbnail_id\n",
    "\n",
    "        # check if thumbnail is already downloaded\n",
    "        if os.path.exists(file_path):\n",
    "            pass\n",
    "        else:\n",
    "            # download and save thumbnail \n",
    "            urllib.request.urlretrieve(url, file_path)\n",
    "\n",
    "    except urllib.error.URLError as e:\n",
    "\n",
    "        df_w_jgp.at[iterator,\"thumbnail_link\"] = np.NAN\n",
    "        # print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "for i in tqdm(range (0, len(df))):\n",
    "\n",
    "    # get thumbnail url\n",
    "    url = df.iloc[i][\"thumbnail_link\"]\n",
    "\n",
    "    # safe thumnail and write path into df\n",
    "    load_and_save_thumbnail(url, i)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(df):\n",
    "    \n",
    "    # Handling Missing Values\n",
    "\n",
    "    if df.isnull().any().any() or df.isna().any().any():\n",
    "\n",
    "        num = df.isnull().sum().sum() + df.isna().sum().sum() # Count Missing Values\n",
    "\n",
    "        print(\">>>\",num, \"Missing Values are beeing handeled\")\n",
    "\n",
    "        #df.dropna() # Drop rows with missing values\n",
    "        #df.fillna(value) # Fill missing values with a specific value\n",
    "\n",
    "    else:\n",
    "        print(\">>> No Missing Values detected\")\n",
    "        \n",
    "    # Remove Duplicate\n",
    "\n",
    "    if df.duplicated().any():\n",
    "\n",
    "        num = df.duplicated().sum() # Count Duplicates\n",
    "\n",
    "        print(\">>>\",num, \"Duplicates are beeing handeled\")\n",
    "\n",
    "        df.drop_duplicates()\n",
    "\n",
    "    else:\n",
    "        print(\">>> No Duplicates detected\")\n",
    "\n",
    "    # Handling Outliers\n",
    "\n",
    "\n",
    "    # Drop Unnececary Columns\n",
    "\n",
    "    df = df.drop(['video_id', 'trending_date', 'thumbnail_link', 'publish_time'], axis=1)\n",
    "\n",
    "    # Convert Data Types \n",
    "\n",
    "    # print( df.dtypes ) # check data types\n",
    "\n",
    "    # Convert 'date_column' to datetime\n",
    "    #df['trending_date'] = pd.to_datetime(df['trending_date'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "    # Convert 'timestamp_column' to timestamp\n",
    "    #df['publish_time'] = pd.to_datetime(df['publish_time'], infer_datetime_format=True)\n",
    "\n",
    "    for column in df:\n",
    "\n",
    "        # Check if column is of type bool\n",
    "        if df[column].dtype == 'bool':\n",
    "            df[column] = df[column].astype(int)\n",
    "\n",
    "    # Check preprocessed data\n",
    "\n",
    "    print(\">>> Updated Data Types \\n\", df.dtypes)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define String Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[5]</td>\n",
       "      <td>[1, 3, 2]</td>\n",
       "      <td>[146, 229, 13, 147, 55, 40, 230]</td>\n",
       "      <td>[460]</td>\n",
       "      <td>10</td>\n",
       "      <td>[2, 1, 223, 7, 19, 4]</td>\n",
       "      <td>[179, 575, 41, 406, 1686, 1687, 1688, 229]</td>\n",
       "      <td>17158579</td>\n",
       "      <td>787425</td>\n",
       "      <td>43420</td>\n",
       "      <td>125882</td>\n",
       "      <td>n1WpP7iowLc</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[4450, 43, 1283, 616, 11, 463, 205, 2124, 28, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[6]</td>\n",
       "      <td>[1, 3, 2]</td>\n",
       "      <td>[231, 232, 233, 114, 234]</td>\n",
       "      <td>[461]</td>\n",
       "      <td>23</td>\n",
       "      <td>[2, 1, 59, 7, 7, 4]</td>\n",
       "      <td>[762, 456, 168, 168, 313, 763, 867, 1689, 137,...</td>\n",
       "      <td>1014651</td>\n",
       "      <td>127794</td>\n",
       "      <td>1688</td>\n",
       "      <td>13030</td>\n",
       "      <td>0dBIkQ4Mz1M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[856, 535, 13, 1066, 12, 2257, 2637, 129, 231,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[7]</td>\n",
       "      <td>[1, 3, 2]</td>\n",
       "      <td>[148, 235, 236, 237, 238, 239, 240, 241]</td>\n",
       "      <td>[108, 109]</td>\n",
       "      <td>23</td>\n",
       "      <td>[2, 1, 167, 60, 24, 4]</td>\n",
       "      <td>[457, 408, 353, 354, 121, 764, 457, 408, 86, 3...</td>\n",
       "      <td>3191434</td>\n",
       "      <td>146035</td>\n",
       "      <td>5339</td>\n",
       "      <td>8181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[54, 63, 1310, 30, 1068, 1, 76, 68, 7, 6, 14, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[8]</td>\n",
       "      <td>[1, 3, 2]</td>\n",
       "      <td>[16, 242, 21, 243, 244]</td>\n",
       "      <td>[163]</td>\n",
       "      <td>24</td>\n",
       "      <td>[2, 1, 81, 10, 90, 4]</td>\n",
       "      <td>[737, 1698, 1029, 461, 64, 767, 33, 1699, 1700...</td>\n",
       "      <td>2095828</td>\n",
       "      <td>132239</td>\n",
       "      <td>1989</td>\n",
       "      <td>17518</td>\n",
       "      <td>d380meD0W0M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[51, 197, 274, 362, 13, 607, 837, 96, 982, 37,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[19, 20]</td>\n",
       "      <td>[1, 3, 2]</td>\n",
       "      <td>[245, 476, 149, 18, 42, 15]</td>\n",
       "      <td>[111, 197]</td>\n",
       "      <td>10</td>\n",
       "      <td>[2, 1, 1250, 61, 5, 4]</td>\n",
       "      <td>[2516, 409, 768, 2517, 81, 2518, 31, 1335, 31,...</td>\n",
       "      <td>33523622</td>\n",
       "      <td>1634130</td>\n",
       "      <td>21082</td>\n",
       "      <td>85067</td>\n",
       "      <td>2Vv-BfVoq4g</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[6507, 7, 1191, 6508, 1301, 529, 6509, 7, 6510...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>[494]</td>\n",
       "      <td>[1, 5, 2]</td>\n",
       "      <td>[2374, 317, 28, 7, 6, 2375, 134, 919]</td>\n",
       "      <td>[2724, 1077]</td>\n",
       "      <td>22</td>\n",
       "      <td>[2, 1, 1274, 36, 17, 4]</td>\n",
       "      <td>[557, 1457, 238, 557, 153, 1457, 557, 49, 557,...</td>\n",
       "      <td>52205</td>\n",
       "      <td>164</td>\n",
       "      <td>27</td>\n",
       "      <td>93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[6410, 13, 1711, 242, 9284, 1744, 2686, 5, 36,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>[95]</td>\n",
       "      <td>[1, 5, 2]</td>\n",
       "      <td>[817, 818, 13, 819, 820, 821]</td>\n",
       "      <td>[289, 1099, 1100, 20, 1101]</td>\n",
       "      <td>25</td>\n",
       "      <td>[2, 1, 148, 32, 20, 4]</td>\n",
       "      <td>[1304, 1305, 3168, 277, 1303, 554, 1216, 530, ...</td>\n",
       "      <td>21839</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>27</td>\n",
       "      <td>lSozbwZmq74</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[3, 8627, 2239, 8628, 129, 1373, 156, 19, 3, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>[108]</td>\n",
       "      <td>[1, 5, 2]</td>\n",
       "      <td>[868, 45, 365, 869, 870, 84, 871, 872, 873, 874]</td>\n",
       "      <td>[1113]</td>\n",
       "      <td>24</td>\n",
       "      <td>[2, 1, 283, 25, 49, 4]</td>\n",
       "      <td>[998, 999, 238, 1233, 1236, 1235, 3246, 1234, ...</td>\n",
       "      <td>338908</td>\n",
       "      <td>25407</td>\n",
       "      <td>228</td>\n",
       "      <td>3184</td>\n",
       "      <td>vIVaLtJmyPs</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[3, 1378, 1132, 36, 2201, 1644, 116, 1506, 45,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>[5]</td>\n",
       "      <td>[1, 5, 2]</td>\n",
       "      <td>[146, 229, 13, 147, 55, 40, 230]</td>\n",
       "      <td>[460]</td>\n",
       "      <td>10</td>\n",
       "      <td>[2, 1, 223, 7, 19, 4]</td>\n",
       "      <td>[179, 575, 41, 406, 1686, 1687, 1688, 229]</td>\n",
       "      <td>22702386</td>\n",
       "      <td>869304</td>\n",
       "      <td>50018</td>\n",
       "      <td>123235</td>\n",
       "      <td>n1WpP7iowLc</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[4450, 43, 1283, 616, 11, 463, 205, 2124, 28, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>[93, 94]</td>\n",
       "      <td>[1, 5, 2]</td>\n",
       "      <td>[203, 815, 816, 73]</td>\n",
       "      <td>[1098]</td>\n",
       "      <td>10</td>\n",
       "      <td>[2, 41, 1264, 71, 46, 4]</td>\n",
       "      <td>[839, 1215, 340, 57, 3158, 97, 3159, 181, 3160...</td>\n",
       "      <td>18764</td>\n",
       "      <td>79</td>\n",
       "      <td>278</td>\n",
       "      <td>65</td>\n",
       "      <td>AT_XoYrpcDU</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[3059, 498, 57, 1371, 1687, 9, 1371, 1687, 154...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     video_id trending_date                                             title   \n",
       "0         [5]     [1, 3, 2]                  [146, 229, 13, 147, 55, 40, 230]  \\\n",
       "1         [6]     [1, 3, 2]                         [231, 232, 233, 114, 234]   \n",
       "2         [7]     [1, 3, 2]          [148, 235, 236, 237, 238, 239, 240, 241]   \n",
       "3         [8]     [1, 3, 2]                           [16, 242, 21, 243, 244]   \n",
       "4    [19, 20]     [1, 3, 2]                       [245, 476, 149, 18, 42, 15]   \n",
       "..        ...           ...                                               ...   \n",
       "495     [494]     [1, 5, 2]             [2374, 317, 28, 7, 6, 2375, 134, 919]   \n",
       "496      [95]     [1, 5, 2]                     [817, 818, 13, 819, 820, 821]   \n",
       "497     [108]     [1, 5, 2]  [868, 45, 365, 869, 870, 84, 871, 872, 873, 874]   \n",
       "498       [5]     [1, 5, 2]                  [146, 229, 13, 147, 55, 40, 230]   \n",
       "499  [93, 94]     [1, 5, 2]                               [203, 815, 816, 73]   \n",
       "\n",
       "                   channel_title  category_id              publish_time   \n",
       "0                          [460]           10     [2, 1, 223, 7, 19, 4]  \\\n",
       "1                          [461]           23       [2, 1, 59, 7, 7, 4]   \n",
       "2                     [108, 109]           23    [2, 1, 167, 60, 24, 4]   \n",
       "3                          [163]           24     [2, 1, 81, 10, 90, 4]   \n",
       "4                     [111, 197]           10    [2, 1, 1250, 61, 5, 4]   \n",
       "..                           ...          ...                       ...   \n",
       "495                 [2724, 1077]           22   [2, 1, 1274, 36, 17, 4]   \n",
       "496  [289, 1099, 1100, 20, 1101]           25    [2, 1, 148, 32, 20, 4]   \n",
       "497                       [1113]           24    [2, 1, 283, 25, 49, 4]   \n",
       "498                        [460]           10     [2, 1, 223, 7, 19, 4]   \n",
       "499                       [1098]           10  [2, 41, 1264, 71, 46, 4]   \n",
       "\n",
       "                                                  tags     views    likes   \n",
       "0           [179, 575, 41, 406, 1686, 1687, 1688, 229]  17158579   787425  \\\n",
       "1    [762, 456, 168, 168, 313, 763, 867, 1689, 137,...   1014651   127794   \n",
       "2    [457, 408, 353, 354, 121, 764, 457, 408, 86, 3...   3191434   146035   \n",
       "3    [737, 1698, 1029, 461, 64, 767, 33, 1699, 1700...   2095828   132239   \n",
       "4    [2516, 409, 768, 2517, 81, 2518, 31, 1335, 31,...  33523622  1634130   \n",
       "..                                                 ...       ...      ...   \n",
       "495  [557, 1457, 238, 557, 153, 1457, 557, 49, 557,...     52205      164   \n",
       "496  [1304, 1305, 3168, 277, 1303, 554, 1216, 530, ...     21839       28   \n",
       "497  [998, 999, 238, 1233, 1236, 1235, 3246, 1234, ...    338908    25407   \n",
       "498         [179, 575, 41, 406, 1686, 1687, 1688, 229]  22702386   869304   \n",
       "499  [839, 1215, 340, 57, 3158, 97, 3159, 181, 3160...     18764       79   \n",
       "\n",
       "     dislikes  comment_count thumbnail_link  comments_disabled   \n",
       "0       43420         125882    n1WpP7iowLc              False  \\\n",
       "1        1688          13030    0dBIkQ4Mz1M              False   \n",
       "2        5339           8181            NaN              False   \n",
       "3        1989          17518    d380meD0W0M              False   \n",
       "4       21082          85067    2Vv-BfVoq4g              False   \n",
       "..        ...            ...            ...                ...   \n",
       "495        27             93            NaN              False   \n",
       "496        18             27    lSozbwZmq74              False   \n",
       "497       228           3184    vIVaLtJmyPs              False   \n",
       "498     50018         123235    n1WpP7iowLc              False   \n",
       "499       278             65    AT_XoYrpcDU              False   \n",
       "\n",
       "     ratings_disabled  video_error_or_removed   \n",
       "0               False                   False  \\\n",
       "1               False                   False   \n",
       "2               False                   False   \n",
       "3               False                   False   \n",
       "4               False                   False   \n",
       "..                ...                     ...   \n",
       "495             False                   False   \n",
       "496             False                   False   \n",
       "497             False                   False   \n",
       "498             False                   False   \n",
       "499             False                   False   \n",
       "\n",
       "                                           description  \n",
       "0    [4450, 43, 1283, 616, 11, 463, 205, 2124, 28, ...  \n",
       "1    [856, 535, 13, 1066, 12, 2257, 2637, 129, 231,...  \n",
       "2    [54, 63, 1310, 30, 1068, 1, 76, 68, 7, 6, 14, ...  \n",
       "3    [51, 197, 274, 362, 13, 607, 837, 96, 982, 37,...  \n",
       "4    [6507, 7, 1191, 6508, 1301, 529, 6509, 7, 6510...  \n",
       "..                                                 ...  \n",
       "495  [6410, 13, 1711, 242, 9284, 1744, 2686, 5, 36,...  \n",
       "496  [3, 8627, 2239, 8628, 129, 1373, 156, 19, 3, 3...  \n",
       "497  [3, 1378, 1132, 36, 2201, 1644, 116, 1506, 45,...  \n",
       "498  [4450, 43, 1283, 616, 11, 463, 205, 2124, 28, ...  \n",
       "499  [3059, 498, 57, 1371, 1687, 9, 1371, 1687, 154...  \n",
       "\n",
       "[500 rows x 16 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w_jgp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(df_cont):# encode remaining objects\n",
    "\n",
    "    tokenizer = Tokenizer(\n",
    "        num_words=10000,\n",
    "        filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "    )\n",
    "\n",
    "    for column in df:\n",
    "\n",
    "        # Check if column is of type object\n",
    "        if df[column].dtype == 'object' and column != \"video_id\":\n",
    "\n",
    "            df[column] = df[column].astype(str)\n",
    "\n",
    "            print(f\">>> {column} is of type object and will be encoded\")\n",
    "\n",
    "            tokenizer.fit_on_texts(df[column])\n",
    "\n",
    "            # Get the word index\n",
    "            word_index = tokenizer.word_index\n",
    "\n",
    "            # Convert texts to sequences\n",
    "            sequences = tokenizer.texts_to_sequences(df[column])\n",
    "\n",
    "            df_cont[column] = sequences\n",
    "\n",
    "            df_cont\n",
    "\n",
    "            # split sequences into seperate columns\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    for column in df_cont:\n",
    "\n",
    "            # Check if column is of type object\n",
    "            if df_cont[column].dtype == 'object':\n",
    "\n",
    "                # Create separate columns for each element in the list\n",
    "                df_expanded = pd.DataFrame(df_cont[column].to_list(), columns=[f\"{column}_{i+1}\" for i in range(df_cont[column].str.len().max())])\n",
    "                \n",
    "                # Concatenate expanded columns with the original DataFrame\n",
    "                df_cont = pd.concat([df_cont.drop(column, axis=1), df_expanded], axis=1)\n",
    "                \n",
    "    return df_cont\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Functions and save final DataFrame as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/dataset_w_jpg.csv\n",
      ">>> 29236 Missing Values are beeing handeled\n",
      ">>> 221 Duplicates are beeing handeled\n",
      ">>> Updated Data Types \n",
      " title                      object\n",
      "channel_title              object\n",
      "category_id               float64\n",
      "tags                       object\n",
      "views                     float64\n",
      "likes                     float64\n",
      "dislikes                  float64\n",
      "comment_count             float64\n",
      "comments_disabled          object\n",
      "ratings_disabled           object\n",
      "video_error_or_removed     object\n",
      "description                object\n",
      "dtype: object\n",
      ">>> video_id is of type object and will be encoded\n",
      ">>> trending_date is of type object and will be encoded\n",
      ">>> title is of type object and will be encoded\n",
      ">>> channel_title is of type object and will be encoded\n",
      ">>> publish_time is of type object and will be encoded\n",
      ">>> tags is of type object and will be encoded\n",
      ">>> thumbnail_link is of type object and will be encoded\n",
      ">>> comments_disabled is of type object and will be encoded\n",
      ">>> ratings_disabled is of type object and will be encoded\n",
      ">>> video_error_or_removed is of type object and will be encoded\n",
      ">>> description is of type object and will be encoded\n",
      "../Data/CAvideos.csv\n",
      ">>> 2592 Missing Values are beeing handeled\n",
      ">>> No Duplicates detected\n",
      ">>> Updated Data Types \n",
      " title                     object\n",
      "channel_title             object\n",
      "category_id                int64\n",
      "tags                      object\n",
      "views                      int64\n",
      "likes                      int64\n",
      "dislikes                   int64\n",
      "comment_count              int64\n",
      "comments_disabled          int64\n",
      "ratings_disabled           int64\n",
      "video_error_or_removed     int64\n",
      "description               object\n",
      "dtype: object\n",
      ">>> video_id is of type object and will be encoded\n",
      ">>> trending_date is of type object and will be encoded\n",
      ">>> title is of type object and will be encoded\n",
      ">>> channel_title is of type object and will be encoded\n",
      ">>> publish_time is of type object and will be encoded\n",
      ">>> tags is of type object and will be encoded\n",
      ">>> thumbnail_link is of type object and will be encoded\n",
      ">>> description is of type object and will be encoded\n",
      "../Data/USvideos.csv\n",
      ">>> 1140 Missing Values are beeing handeled\n",
      ">>> 48 Duplicates are beeing handeled\n",
      ">>> Updated Data Types \n",
      " title                     object\n",
      "channel_title             object\n",
      "category_id                int64\n",
      "tags                      object\n",
      "views                      int64\n",
      "likes                      int64\n",
      "dislikes                   int64\n",
      "comment_count              int64\n",
      "comments_disabled          int64\n",
      "ratings_disabled           int64\n",
      "video_error_or_removed     int64\n",
      "description               object\n",
      "dtype: object\n",
      ">>> video_id is of type object and will be encoded\n",
      ">>> trending_date is of type object and will be encoded\n",
      ">>> title is of type object and will be encoded\n",
      ">>> channel_title is of type object and will be encoded\n",
      ">>> publish_time is of type object and will be encoded\n",
      ">>> tags is of type object and will be encoded\n",
      ">>> thumbnail_link is of type object and will be encoded\n",
      ">>> description is of type object and will be encoded\n",
      "../Data/GBvideos.csv\n",
      ">>> 1224 Missing Values are beeing handeled\n",
      ">>> 171 Duplicates are beeing handeled\n",
      ">>> Updated Data Types \n",
      " title                     object\n",
      "channel_title             object\n",
      "category_id                int64\n",
      "tags                      object\n",
      "views                      int64\n",
      "likes                      int64\n",
      "dislikes                   int64\n",
      "comment_count              int64\n",
      "comments_disabled          int64\n",
      "ratings_disabled           int64\n",
      "video_error_or_removed     int64\n",
      "description               object\n",
      "dtype: object\n",
      ">>> video_id is of type object and will be encoded\n",
      ">>> trending_date is of type object and will be encoded\n",
      ">>> title is of type object and will be encoded\n",
      ">>> channel_title is of type object and will be encoded\n",
      ">>> publish_time is of type object and will be encoded\n",
      ">>> tags is of type object and will be encoded\n",
      ">>> thumbnail_link is of type object and will be encoded\n",
      ">>> description is of type object and will be encoded\n",
      "        category_id       views      likes  dislikes  comment_count  title_1   \n",
      "0              10.0  17158579.0   787425.0   43420.0       125882.0    764.0  \\\n",
      "1              23.0   1014651.0   127794.0    1688.0        13030.0   6061.0   \n",
      "2              23.0   3191434.0   146035.0    5339.0         8181.0    743.0   \n",
      "3              24.0   2095828.0   132239.0    1989.0        17518.0     52.0   \n",
      "4              10.0  33523622.0  1634130.0   21082.0        85067.0    549.0   \n",
      "...             ...         ...        ...       ...            ...      ...   \n",
      "161954         10.0  25066952.0   268088.0   12783.0         9933.0    739.0   \n",
      "161955         10.0   1492219.0    61998.0   13781.0        24330.0   1871.0   \n",
      "161956         10.0  29641412.0   394830.0    8892.0        19988.0    652.0   \n",
      "161957         24.0  14317515.0   151870.0   45875.0        26766.0   1867.0   \n",
      "161958         10.0    607552.0    18271.0     274.0         1423.0    579.0   \n",
      "\n",
      "        title_2  title_3  title_4  title_5  ...  thumbnail_link_7  country   \n",
      "0         661.0     18.0    437.0    124.0  ...               NaN        0  \\\n",
      "1         225.0    718.0    647.0   2093.0  ...               NaN        0   \n",
      "2        1764.0    777.0   1402.0    465.0  ...               NaN        0   \n",
      "3        2159.0     45.0    609.0   5450.0  ...               NaN        0   \n",
      "4         662.0    338.0     22.0     59.0  ...               NaN        0   \n",
      "...         ...      ...      ...      ...  ...               ...      ...   \n",
      "161954    740.0    963.0     18.0    333.0  ...               7.0        3   \n",
      "161955   1872.0     74.0     21.0     63.0  ...               7.0        3   \n",
      "161956    709.0   1598.0      7.0     10.0  ...            3908.0        3   \n",
      "161957   1868.0   1869.0   1870.0     57.0  ...               7.0        3   \n",
      "161958     45.0     55.0    655.0   5597.0  ...               8.0        3   \n",
      "\n",
      "        comments_disabled  ratings_disabled  video_error_or_removed   \n",
      "0                     NaN               NaN                     NaN  \\\n",
      "1                     NaN               NaN                     NaN   \n",
      "2                     NaN               NaN                     NaN   \n",
      "3                     NaN               NaN                     NaN   \n",
      "4                     NaN               NaN                     NaN   \n",
      "...                   ...               ...                     ...   \n",
      "161954                0.0               0.0                     0.0   \n",
      "161955                0.0               0.0                     0.0   \n",
      "161956                0.0               0.0                     0.0   \n",
      "161957                0.0               0.0                     0.0   \n",
      "161958                0.0               0.0                     0.0   \n",
      "\n",
      "        description_915  thumbnail_link_8  thumbnail_link_9   \n",
      "0                   NaN               NaN               NaN  \\\n",
      "1                   NaN               NaN               NaN   \n",
      "2                   NaN               NaN               NaN   \n",
      "3                   NaN               NaN               NaN   \n",
      "4                   NaN               NaN               NaN   \n",
      "...                 ...               ...               ...   \n",
      "161954              NaN               8.0               NaN   \n",
      "161955              NaN               8.0               NaN   \n",
      "161956              NaN               7.0               8.0   \n",
      "161957              NaN               8.0               NaN   \n",
      "161958              NaN               NaN               NaN   \n",
      "\n",
      "        thumbnail_link_10  thumbnail_link_11  \n",
      "0                     NaN                NaN  \n",
      "1                     NaN                NaN  \n",
      "2                     NaN                NaN  \n",
      "3                     NaN                NaN  \n",
      "4                     NaN                NaN  \n",
      "...                   ...                ...  \n",
      "161954                NaN                NaN  \n",
      "161955                NaN                NaN  \n",
      "161956                NaN                NaN  \n",
      "161957                NaN                NaN  \n",
      "161958                NaN                NaN  \n",
      "\n",
      "[161959 rows x 1156 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder_path = \"../Data\"  # Replace with the path to your folder\n",
    "final_df = []  # List to store the DataFrames\n",
    "\n",
    "iterator = 0\n",
    "# Iterate over files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.csv') and file_name != 'final_dataset.csv':  # Process only CSV files\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        print(file_path)\n",
    "\n",
    "        # Read the CSV file and create a DataFrame\n",
    "        df = pd.read_csv(file_path, encoding='latin-1')\n",
    "\n",
    "        cleaned_df = data_cleaning(df)\n",
    "\n",
    "        encoded_df = encoding(cleaned_df)\n",
    "\n",
    "        encoded_df[\"country\"] = iterator # file_name[:3]\n",
    "\n",
    "        iterator += 1\n",
    "\n",
    "        # Add the DataFrame to the list\n",
    "        final_df.append(encoded_df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(final_df, ignore_index=True)\n",
    "\n",
    "# Print the combined DataFrame\n",
    "print(combined_df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export final df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['video_id', 'trending_date', 'title', 'channel_title', 'category_id',\n",
       "       'publish_time', 'tags', 'views', 'likes', 'dislikes', 'comment_count',\n",
       "       'thumbnail_link', 'comments_disabled', 'ratings_disabled',\n",
       "       'video_error_or_removed', 'description'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w_jgp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> video_id is of type object and will be encoded\n",
      ">>> trending_date is of type object and will be encoded\n",
      ">>> title is of type object and will be encoded\n",
      ">>> channel_title is of type object and will be encoded\n",
      ">>> publish_time is of type object and will be encoded\n",
      ">>> tags is of type object and will be encoded\n",
      ">>> description is of type object and will be encoded\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m encoded_df \u001b[39m=\u001b[39m encoding(df_w_jgp)\n",
      "Cell \u001b[0;32mIn[14], line 40\u001b[0m, in \u001b[0;36mencoding\u001b[0;34m(df_cont)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mfor\u001b[39;00m column \u001b[39min\u001b[39;00m df_cont:\n\u001b[1;32m     35\u001b[0m \n\u001b[1;32m     36\u001b[0m         \u001b[39m# Check if column is of type object\u001b[39;00m\n\u001b[1;32m     37\u001b[0m         \u001b[39mif\u001b[39;00m df_cont[column]\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     38\u001b[0m \n\u001b[1;32m     39\u001b[0m             \u001b[39m# Create separate columns for each element in the list\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m             df_expanded \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(df_cont[column]\u001b[39m.\u001b[39mto_list(), columns\u001b[39m=\u001b[39m[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mcolumn\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39;49m(df_cont[column]\u001b[39m.\u001b[39;49mstr\u001b[39m.\u001b[39;49mlen()\u001b[39m.\u001b[39;49mmax())])\n\u001b[1;32m     42\u001b[0m             \u001b[39m# Concatenate expanded columns with the original DataFrame\u001b[39;00m\n\u001b[1;32m     43\u001b[0m             df_cont \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([df_cont\u001b[39m.\u001b[39mdrop(column, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), df_expanded], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "encoded_df = encoding(df_w_jgp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN values with 0\n",
    "#df_w_jgp= df_w_jgp.fillna(0)\n",
    "\n",
    "df_cnn = df_w_jgp[['views', 'thumbnail_link']]\n",
    "\n",
    "# Save final df as csv\n",
    "csv_path = \"../Data/final_dataset_cnn.csv\"\n",
    "df_cnn.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN values with 0\n",
    "combined_df= combined_df.fillna(0)\n",
    "\n",
    "# Save final df as csv\n",
    "csv_path = \"../Data/final_dataset.csv\"\n",
    "combined_df.to_csv(csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
